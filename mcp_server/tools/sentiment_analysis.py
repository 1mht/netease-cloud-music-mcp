"""
æƒ…æ„Ÿåˆ†æå·¥å…·æ¨¡å—
æ”¯æŒè¯„è®ºæƒ…æ„Ÿåˆ†æã€æ­Œæ›²å¯¹æ¯”ã€ç½‘æŠ‘äº‘æ’è¡Œç­‰åŠŸèƒ½
ä½¿ç”¨ç­–ç•¥æ¨¡å¼æ”¯æŒæ¨¡å‹çƒ­æ’æ‹”ï¼ˆSnowNLP / è‡ªå®šä¹‰æ¨¡å‹ï¼‰
"""

import sys
import os
from abc import ABC, abstractmethod

# æ·»åŠ  netease_cloud_music åˆ° Python è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
netease_path = os.path.join(project_root, 'netease_cloud_music')
if netease_path not in sys.path:
    sys.path.insert(0, netease_path)

from database import init_db, Song, Comment
from typing import Optional, List, Dict, Any
from .workflow_errors import workflow_error  # v0.6.6: ç»Ÿä¸€é”™è¯¯å¤„ç†

# ===== ç»Ÿè®¡å­¦å¸¸é‡ =====
MAX_ANALYSIS_SIZE = 5000           # å†…å­˜å®‰å…¨ï¼šæœ€å¤§åˆ†ææ•°é‡ï¼ˆé˜²æ­¢çˆ†æ ˆï¼‰
DEGRADED_MODE_THRESHOLD = 5        # â‰¤5æ¡ï¼šé™çº§æ¨¡å¼ï¼ˆå±•ç¤ºï¼Œä¸åˆ†æï¼‰
MIN_VIABLE_SIZE = 30               # 30æ¡ï¼šæœ€å°å¯åˆ†æï¼ˆæä½ç½®ä¿¡åº¦ï¼‰
RECOMMENDED_SIZE = 100             # 100æ¡ï¼šå»ºè®®çº¿ï¼ˆæ­£å¸¸ç½®ä¿¡åº¦ï¼‰

# ===== v0.7.1: Workflow å¼ºåˆ¶æ ¡éªŒé˜ˆå€¼ =====
WORKFLOW_MIN_REQUIRED = 100        # ç¡¬æ€§æœ€ä½è¦æ±‚ï¼šä½äºæ­¤å€¼è‡ªåŠ¨é‡‡æ ·ï¼ˆv2.2å»ºè®®100æ¡ï¼‰


def check_sample_size(comments_count: int, song_id: str, comments_list: list = None) -> Optional[dict]:
    """æ£€æŸ¥æ ·æœ¬é‡å¹¶è¿”å›ç›¸åº”ç­–ç•¥ï¼ˆåˆ†å±‚é™çº§ï¼‰

    Args:
        comments_count: è¯„è®ºæ•°é‡
        song_id: æ­Œæ›²ID
        comments_list: è¯„è®ºåˆ—è¡¨ï¼ˆç”¨äºé™çº§æ¨¡å¼è¿”å›è¯„è®ºæ–‡æœ¬ï¼‰

    Returns:
        å¦‚æœéœ€è¦é™çº§/è­¦å‘Šï¼Œè¿”å›å¯¹åº”å­—å…¸ï¼›å¦åˆ™è¿”å› None
    """
    # æƒ…å†µ1ï¼šâ‰¤5æ¡ - é™çº§æ¨¡å¼ï¼ˆä¸åšç»Ÿè®¡åˆ†æï¼Œç›´æ¥è¿”å›è¯„è®ºæ–‡æœ¬ï¼‰
    if comments_count <= DEGRADED_MODE_THRESHOLD:
        preview = []
        if comments_list:
            preview = [
                {
                    "content": c.content,
                    "liked_count": c.liked_count,
                    "time": str(c.time) if hasattr(c, 'time') else None
                }
                for c in comments_list[:5]
            ]

        return {
            "status": "error",
            "error_type": "insufficient_sample",
            "mode": "simple_display",
            "count": comments_count,
            "message": f"âš ï¸ è¯„è®ºé‡æå°‘ï¼ˆ{comments_count}æ¡ï¼‰ï¼Œæ— æ³•è¿›è¡Œç»Ÿè®¡åˆ†æ",
            "comments_preview": preview,
            "explanation": {
                "why_no_analysis": "2-5æ¡è¯„è®ºæ— ç»Ÿè®¡æ„ä¹‰ï¼Œä»»ä½•åˆ†æç»“è®ºéƒ½ä¸å¯é ",
                "what_you_can_do": [
                    "ç›´æ¥é˜…è¯»ä»¥ä¸Šè¯„è®ºå†…å®¹",
                    "ç­‰å¾…æ›´å¤šç”¨æˆ·è¯„è®ºåå†åˆ†æ",
                    f"çˆ¬å–æ›´å¤šæ•°æ®ï¼šcrawl_all_comments_for_song(song_id='{song_id}')",
                    "åˆ†æå…¶ä»–è¯„è®ºæ›´å¤šçš„æ­Œæ›²"
                ]
            },
            "next_step": f"å¦‚éœ€æŸ¥çœ‹å®Œæ•´è¯„è®ºï¼Œè°ƒç”¨ get_all_comments_tool(song_id='{song_id}')"
        }

    # æƒ…å†µ2-4ï¼šè¿”å› Noneï¼Œä½†ä¼šåœ¨ä¸»å‡½æ•°ä¸­æ·»åŠ è­¦å‘Šæ ‡è®°
    return None


def get_session():
    """è·å–æ•°æ®åº“session"""
    db_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))),
                          'data', 'music_data_v2.db')
    return init_db(f'sqlite:///{db_path}')


# ===== ç­–ç•¥æ¨¡å¼ï¼šæ”¯æŒå¤šç§åˆ†æå¼•æ“ =====

class SentimentAnalyzer(ABC):
    """æƒ…æ„Ÿåˆ†æå™¨åŸºç±»"""
    @abstractmethod
    def analyze(self, text: str) -> float:
        """è¿”å›æƒ…æ„Ÿåˆ†æ•° 0-1ï¼ˆ0=æè´Ÿé¢ï¼Œ1=ææ­£é¢ï¼‰"""
        pass


class SnowNLPAnalyzer(SentimentAnalyzer):
    """SnowNLP å®ç°ï¼ˆç®€å•å¿«é€Ÿï¼‰"""
    def __init__(self):
        try:
            from snownlp import SnowNLP
            self.SnowNLP = SnowNLP
        except ImportError:
            raise ImportError("è¯·å…ˆå®‰è£… snownlp: pip install snownlp")

    def analyze(self, text: str) -> float:
        s = self.SnowNLP(text)
        return s.sentiments


class CustomModelAnalyzer(SentimentAnalyzer):
    """è‡ªå®šä¹‰æ¨¡å‹æ¥å£ï¼ˆé¢„ç•™ï¼Œç”¨äºè¯¾è®¾æ‰©å±•ï¼‰

    ç¤ºä¾‹ï¼šåŠ è½½ BERT/RoBERTa æ¨¡å‹
    """
    def __init__(self, model_path: str):
        # TODO: åŠ è½½ä½ çš„è‡ªå®šä¹‰æ¨¡å‹
        # import torch
        # self.model = torch.load(model_path)
        # self.tokenizer = ...
        self.model_path = model_path
        print(f"[INFO] è‡ªå®šä¹‰æ¨¡å‹æ¥å£ï¼ˆé¢„ç•™ï¼‰: {model_path}")

    def analyze(self, text: str) -> float:
        # TODO: è°ƒç”¨è‡ªå®šä¹‰æ¨¡å‹è¿›è¡Œæ¨ç†
        # inputs = self.tokenizer(text, return_tensors='pt')
        # outputs = self.model(**inputs)
        # score = torch.softmax(outputs.logits, dim=1)[0][1].item()
        # return score

        # æš‚æ—¶è¿”å›é»˜è®¤å€¼
        print("[WARNING] è‡ªå®šä¹‰æ¨¡å‹åŠŸèƒ½å°šæœªå®ç°ï¼Œä½¿ç”¨ SnowNLP æ›¿ä»£")
        return SnowNLPAnalyzer().analyze(text)


def get_analyzer(model_type: str = "simple") -> SentimentAnalyzer:
    """å·¥å‚å‡½æ•°ï¼šæ ¹æ®ç±»å‹è¿”å›åˆ†æå™¨

    Args:
        model_type: "simple" (SnowNLP) | "advanced" (è‡ªå®šä¹‰æ¨¡å‹)

    Returns:
        SentimentAnalyzer å®ä¾‹
    """
    if model_type == "simple":
        return SnowNLPAnalyzer()
    elif model_type == "advanced":
        # é¢„ç•™ï¼šåŠ è½½è‡ªå®šä¹‰æ¨¡å‹
        return CustomModelAnalyzer("models/sentiment_bert.pth")
    else:
        raise ValueError(f"æœªçŸ¥æ¨¡å‹ç±»å‹: {model_type}")


# ===== æ ¸å¿ƒåˆ†æå‡½æ•° =====

def analyze_sentiment(song_id: str, model_type: str = "simple") -> dict:
    """åˆ†ææ­Œæ›²è¯„è®ºçš„æƒ…æ„Ÿåˆ†å¸ƒ

    âœ… v0.7.1: æ”¯æŒå†…éƒ¨è‡ªåŠ¨é‡‡æ ·ï¼

    ğŸ“‹ ç®€åŒ–çš„è°ƒç”¨æ–¹å¼:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ ç›´æ¥è°ƒç”¨: analyze_sentiment_tool(song_id)                   â”‚
    â”‚                                                             â”‚
    â”‚ å·¥å…·å†…éƒ¨è‡ªåŠ¨å¤„ç†:                                           â”‚
    â”‚ - æ£€æŸ¥æ•°æ®åº“è¯„è®ºæ•°é‡                                        â”‚
    â”‚ - å¦‚æœ < 100æ¡ â†’ è‡ªåŠ¨è§¦å‘åˆ†å±‚é‡‡æ ·(stratified_v2.2)         â”‚
    â”‚ - é‡‡æ ·è¦†ç›–: çƒ­è¯„15æ¡ + æœ€æ–°100æ¡ + å†å²10å¹´(æ¯å¹´30æ¡)      â”‚
    â”‚ - è¿”å›ç»“æœä¸­åŒ…å« sampling_info å­—æ®µè¯´æ˜é‡‡æ ·è¯¦æƒ…             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    âœ… æ­£ç¡®ç”¨æ³•: ç›´æ¥è°ƒç”¨æ­¤å·¥å…·å³å¯
    â„¹ï¸ å¯é€‰æ­¥éª¤: å…ˆè°ƒç”¨ get_comments_metadata_tool äº†è§£æ•°æ®çŠ¶æ€

    ğŸ“Š é‡‡æ ·ç­–ç•¥ (v2.2):
    - Layer 1: çƒ­è¯„15æ¡ (APIå›ºå®šè¿”å›)
    - Layer 2: æœ€æ–°100æ¡ (offsetç¿»é¡µ)
    - Layer 3: å†å²åˆ†å±‚ (cursoræŒ‰å¹´è·³è½¬ï¼Œæ¯å¹´30æ¡ï¼Œå…±10å¹´)
    - æ€»è®¡: çº¦400æ¡ï¼Œè¦†ç›–æ­Œæ›²å‘å¸ƒä»¥æ¥çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸ

    Args:
        song_id: æ­Œæ›²ID
        model_type: "simple" (SnowNLP) | "advanced" (è‡ªå®šä¹‰æ¨¡å‹)

    Returns:
        {
            "song_id": "185811",
            "song_name": "æ™´å¤©",
            "total_comments": 318,
            "sentiment_distribution": {
                "positive": 215,
                "neutral": 50,
                "negative": 53
            },
            "average_score": 0.65,
            "representative_comments": {...},
            "sampling_info": {  # v0.7.1æ–°å¢
                "auto_sampled": true,
                "strategy": "stratified_v2.2",
                "hot_count": 15,
                "recent_count": 100,
                "historical_count": 203,
                "years_covered": 10
            }
        }
    """
    session = get_session()

    try:
        # 1. è·å–æ­Œæ›²å’Œè¯„è®º
        song = session.query(Song).filter_by(id=song_id).first()
        if not song:
            # v0.6.6: ä½¿ç”¨ç»Ÿä¸€çš„workflowé”™è¯¯
            return workflow_error("song_not_found", "analyze_sentiment_tool")

        comments = session.query(Comment).filter_by(song_id=song_id).all()

        if not comments:
            # v0.6.6: ä½¿ç”¨ç»Ÿä¸€çš„workflowé”™è¯¯
            return workflow_error("no_comments", "analyze_sentiment_tool")

        count = len(comments)

        # ===== v0.7.1: è‡ªåŠ¨åˆ†å±‚é‡‡æ · =====
        # å¦‚æœè¯„è®ºæ•°ä½äºç¡¬æ€§æœ€ä½è¦æ±‚ï¼Œè‡ªåŠ¨è°ƒç”¨åˆ†å±‚é‡‡æ ·
        auto_sampled = False
        sampling_stats = None

        if count < WORKFLOW_MIN_REQUIRED:
            print(f"[è‡ªåŠ¨é‡‡æ ·] æ•°æ®åº“ä»…æœ‰{count}æ¡ï¼Œå¯åŠ¨åˆ†å±‚é‡‡æ ·...")

            try:
                from .pagination_sampling import full_stratified_sample
                sample_result = full_stratified_sample(song_id, analysis_type="sentiment")

                if sample_result.get('all_comments'):
                    # ä½¿ç”¨é‡‡æ ·çš„è¯„è®ºæ›¿ä»£æ•°æ®åº“è¯„è®º
                    sampled_comments = sample_result['all_comments']
                    count = len(sampled_comments)
                    auto_sampled = True
                    sampling_stats = sample_result.get('stats', {})

                    # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼ï¼ˆæ¨¡æ‹ŸCommentå¯¹è±¡çš„å±æ€§ï¼‰
                    comments = []
                    for c in sampled_comments:
                        class CommentLike:
                            def __init__(self, data):
                                self.content = data.get('content', '')
                                self.liked_count = data.get('liked_count', 0)
                                self.timestamp = data.get('timestamp', 0)
                        comments.append(CommentLike(c))

                    print(f"[è‡ªåŠ¨é‡‡æ ·] å®Œæˆ! è·å–{count}æ¡è¯„è®ºï¼Œè¦†ç›–{sampling_stats.get('years_covered', 0)}å¹´")
                else:
                    # é‡‡æ ·å¤±è´¥ï¼Œè¿”å›é”™è¯¯
                    return {
                        "status": "workflow_error",
                        "error_type": "sampling_failed",
                        "message": f"è‡ªåŠ¨é‡‡æ ·å¤±è´¥ï¼Œæ•°æ®åº“ä»…æœ‰{count}æ¡è¯„è®º",
                        "song_id": song_id,
                        "song_name": song.name
                    }
            except Exception as e:
                print(f"[è‡ªåŠ¨é‡‡æ ·] å¼‚å¸¸: {e}")
                return {
                    "status": "workflow_error",
                    "error_type": "sampling_error",
                    "message": f"è‡ªåŠ¨é‡‡æ ·å¼‚å¸¸: {str(e)}",
                    "song_id": song_id,
                    "song_name": song.name
                }

        # ===== Phase 1: å†…å­˜å®‰å…¨æ£€æŸ¥ï¼ˆé˜²æ­¢çˆ†æ ˆï¼‰ =====
        if count > MAX_ANALYSIS_SIZE:
            return {
                "status": "error",
                "error_type": "dataset_too_large",
                "message": f"âš ï¸ æ•°æ®é›†è¿‡å¤§ï¼š{count}æ¡è¯„è®º",
                "current_size": count,
                "max_allowed": MAX_ANALYSIS_SIZE,
                "recommendation": {
                    "action": "ä½¿ç”¨é‡‡æ ·åˆ†æè€Œéå…¨é‡åŠ è½½",
                    "suggested_call": f"get_comments_by_pages_tool(song_id='{song_id}', pages=[1,10,20,30,40])",
                    "expected_sample_size": "çº¦100-200æ¡",
                    "why_sampling": "é‡‡æ ·åˆ†æå¯è·å¾—æ¥è¿‘å…¨é‡çš„ç»Ÿè®¡ç»“æœï¼ŒåŒæ—¶é¿å…å†…å­˜æº¢å‡º"
                }
            }

        # ===== Phase 3: åˆ†å±‚æ ·æœ¬é‡æ£€æŸ¥ï¼ˆé™çº§æ¨¡å¼ï¼‰ =====
        degraded_check = check_sample_size(count, song_id, comments)
        if degraded_check:
            return degraded_check  # é™çº§æ¨¡å¼ç›´æ¥è¿”å›

        print(f"[START] åˆ†æã€Š{song.name}ã€‹çš„è¯„è®ºæƒ…æ„Ÿ...")

        # 2. åˆå§‹åŒ–åˆ†æå™¨
        analyzer = get_analyzer(model_type)

        # 3. åˆ†ææ¯æ¡è¯„è®º
        scores = []
        for comment in comments:
            if len(comment.content) < 5:  # è¿‡æ»¤è¿‡çŸ­è¯„è®º
                continue
            try:
                score = analyzer.analyze(comment.content)
                scores.append({
                    "content": comment.content,
                    "score": score,
                    "liked_count": comment.liked_count
                })
            except Exception as e:
                # è·³è¿‡åˆ†æå¤±è´¥çš„è¯„è®º
                continue

        if not scores:
            return {"status": "error", "message": "æ²¡æœ‰æœ‰æ•ˆçš„è¯„è®ºå¯ä¾›åˆ†æ"}

        # 4. ç»Ÿè®¡
        positive = sum(1 for s in scores if s['score'] >= 0.6)
        negative = sum(1 for s in scores if s['score'] <= 0.4)
        neutral = len(scores) - positive - negative
        avg_score = sum(s['score'] for s in scores) / len(scores)

        # 5. æ‰¾å‡ºä»£è¡¨æ€§è¯„è®º
        scores_sorted = sorted(scores, key=lambda x: x['score'])
        most_negative = scores_sorted[0]
        most_positive = scores_sorted[-1]

        print(f"[OK] åˆ†æå®Œæˆ: æ­£é¢={positive}, ä¸­æ€§={neutral}, è´Ÿé¢={negative}")

        # æ„å»ºåŸºç¡€ç»“æœ
        result = {
            "song_id": song_id,
            "song_name": song.name,
            "total_comments": len(scores),
            "sentiment_distribution": {
                "positive": positive,
                "neutral": neutral,
                "negative": negative
            },
            "average_score": round(avg_score, 3),
            "representative_comments": {
                "most_positive": {
                    "content": most_positive['content'][:80],
                    "score": round(most_positive['score'], 3),
                    "liked_count": most_positive['liked_count']
                },
                "most_negative": {
                    "content": most_negative['content'][:80],
                    "score": round(most_negative['score'], 3),
                    "liked_count": most_negative['liked_count']
                }
            }
        }

        # ===== Phase 3: æ·»åŠ ç½®ä¿¡åº¦æ ‡è®° =====
        if count < MIN_VIABLE_SIZE:
            # 6-29æ¡ï¼šæä½ç½®ä¿¡åº¦
            result["status"] = "success"
            result["confidence"] = "extremely_low"
            result["warning"] = {
                "type": "very_small_sample",
                "message": f"âš ï¸ æ ·æœ¬é‡å¾ˆå°ï¼ˆ{count}æ¡ï¼‰ï¼Œåˆ†æç»“æœä»…ä¾›å‚è€ƒ",
                "reliability": "æä½ - ç»“è®ºå¯èƒ½éšæ–°è¯„è®ºå¤§å¹…å˜åŒ–",
                "suggestion": "å»ºè®®ï¼š1) ä»…ä½œåˆæ­¥äº†è§£ï¼Œ2) çˆ¬å–æ›´å¤šæ•°æ®åé‡æ–°åˆ†æ"
            }
        elif count < RECOMMENDED_SIZE:
            # 30-99æ¡ï¼šä½ç½®ä¿¡åº¦
            result["status"] = "success"
            result["confidence"] = "low"
            result["warning"] = {
                "type": "small_sample",
                "message": f"â„¹ï¸ æ ·æœ¬é‡åå°ï¼ˆ{count}æ¡ï¼‰ï¼Œå»ºè®®è°¨æ…è§£è¯»",
                "reliability": "ä¸­ç­‰ - åŸºæœ¬è¶‹åŠ¿å¯ä¿¡ï¼Œç»†èŠ‚å¯èƒ½æœ‰åå·®",
                "suggestion": "è¾¾åˆ°100æ¡è¯„è®ºååˆ†æä¼šæ›´å¯é "
            }
        else:
            # 100+æ¡ï¼šæ­£å¸¸
            result["status"] = "success"
            result["confidence"] = "normal"
            result["sample_info"] = {
                "count": count,
                "reliability": "æ­£å¸¸ - æ ·æœ¬é‡è¶³å¤Ÿï¼Œç»“è®ºå¯é "
            }

        # ===== v0.7.1: æ·»åŠ é‡‡æ ·ä¿¡æ¯ï¼ˆé€æ˜å±•ç¤ºï¼‰ =====
        if auto_sampled and sampling_stats:
            result["sampling_info"] = {
                "auto_sampled": True,
                "strategy": "stratified_v2.2",
                "hot_count": sampling_stats.get('hot_count', 0),
                "recent_count": sampling_stats.get('recent_count', 0),
                "historical_count": sampling_stats.get('historical_count', 0),
                "total_unique": sampling_stats.get('total_unique', 0),
                "years_covered": sampling_stats.get('years_covered', 0),
                "year_list": sampling_stats.get('year_list', []),
                "note": "æ•°æ®é€šè¿‡è‡ªåŠ¨åˆ†å±‚é‡‡æ ·è·å–ï¼ˆçƒ­è¯„+æœ€æ–°+å†å²cursorè·³è½¬ï¼‰"
            }

        return result

    finally:
        session.close()


def compare_songs(song_id_1: str, song_id_2: str) -> dict:
    """å¯¹æ¯”ä¸¤é¦–æ­Œçš„æƒ…æ„Ÿå·®å¼‚

    Args:
        song_id_1: ç¬¬ä¸€é¦–æ­ŒID
        song_id_2: ç¬¬äºŒé¦–æ­ŒID

    Returns:
        {
            "song_1": {...},
            "song_2": {...},
            "difference": {
                "sentiment_gap": 0.30,
                "conclusion": "ã€Šæ™´å¤©ã€‹æ¯”ã€Šæµ·åº•ã€‹æ›´æ²»æ„ˆ"
            }
        }
    """
    print(f"[START] å¯¹æ¯”ä¸¤é¦–æ­Œçš„æƒ…æ„Ÿ...")

    result1 = analyze_sentiment(song_id_1)
    result2 = analyze_sentiment(song_id_2)

    if result1.get('status') == 'error' or result2.get('status') == 'error':
        return {
            "status": "error",
            "message": "å…¶ä¸­ä¸€é¦–æ­Œæ›²åˆ†æå¤±è´¥",
            "song_1_error": result1.get('message') if result1.get('status') == 'error' else None,
            "song_2_error": result2.get('message') if result2.get('status') == 'error' else None
        }

    gap = result1['average_score'] - result2['average_score']

    # åˆ¤æ–­æƒ…æ„Ÿå€¾å‘
    def get_emotion(score):
        if score >= 0.6:
            return "positive"
        elif score <= 0.4:
            return "negative"
        else:
            return "neutral"

    # ç”Ÿæˆç»“è®º
    if abs(gap) < 0.05:
        conclusion = f"ã€Š{result1['song_name']}ã€‹ä¸ã€Š{result2['song_name']}ã€‹æƒ…æ„Ÿå€¾å‘ç›¸ä¼¼"
    elif gap > 0:
        conclusion = f"ã€Š{result1['song_name']}ã€‹æ¯”ã€Š{result2['song_name']}ã€‹æ›´{'æ²»æ„ˆ' if result1['average_score'] >= 0.6 else 'æ­£é¢'}"
    else:
        conclusion = f"ã€Š{result2['song_name']}ã€‹æ¯”ã€Š{result1['song_name']}ã€‹æ›´{'æ²»æ„ˆ' if result2['average_score'] >= 0.6 else 'æ­£é¢'}"

    print(f"[OK] å¯¹æ¯”å®Œæˆ: {conclusion}")

    return {
        "song_1": {
            "id": result1['song_id'],
            "name": result1['song_name'],
            "avg_sentiment": result1['average_score'],
            "dominant_emotion": get_emotion(result1['average_score']),
            "comment_count": result1['total_comments']
        },
        "song_2": {
            "id": result2['song_id'],
            "name": result2['song_name'],
            "avg_sentiment": result2['average_score'],
            "dominant_emotion": get_emotion(result2['average_score']),
            "comment_count": result2['total_comments']
        },
        "difference": {
            "sentiment_gap": round(abs(gap), 3),
            "conclusion": conclusion
        }
    }


def find_wangyiyun_songs(limit: int = 10) -> list:
    """æ‰¾å‡ºæ•°æ®åº“ä¸­æœ€"ç½‘æŠ‘äº‘"çš„æ­Œæ›²

    Args:
        limit: è¿”å›å‰Né¦–ï¼ˆé»˜è®¤10é¦–ï¼‰

    Returns:
        [
            {
                "rank": 1,
                "song_id": "123456",
                "song_name": "æµ·åº•",
                "artist": "ä¸€é¢—å°è‘±",
                "avg_sentiment": 0.28,
                "negative_ratio": 0.75,
                "wangyiyun_score": 0.85,
                "sample_comment": "..."
            },
            ...
        ]
    """
    session = get_session()

    try:
        print(f"[START] æŸ¥æ‰¾æœ€ç½‘æŠ‘äº‘çš„æ­Œæ›²...")

        songs = session.query(Song).all()
        results = []

        for song in songs:
            comments = session.query(Comment).filter_by(song_id=song.id).all()
            if not comments:
                continue

            # åˆ†ææƒ…æ„Ÿ
            analyzer = get_analyzer("simple")
            scores = []
            valid_comments = []

            for comment in comments:
                if len(comment.content) >= 5:
                    try:
                        score = analyzer.analyze(comment.content)
                        scores.append(score)
                        valid_comments.append(comment)
                    except:
                        continue

            if not scores:
                continue

            # è®¡ç®—æŒ‡æ ‡
            avg_score = sum(scores) / len(scores)
            negative_ratio = sum(1 for s in scores if s <= 0.4) / len(scores)

            # "ç½‘æŠ‘äº‘æŒ‡æ•°" = (1 - å¹³å‡æƒ…æ„Ÿ) * è´Ÿé¢å æ¯”
            # è¿™ä¸ªå…¬å¼ç¡®ä¿ï¼šæƒ…æ„Ÿè¶Šè´Ÿé¢ + è´Ÿé¢è¯„è®ºå æ¯”è¶Šé«˜ = è¶Šç½‘æŠ‘äº‘
            wangyiyun_score = (1 - avg_score) * negative_ratio

            # æ‰¾ä¸€æ¡æœ€è´Ÿé¢çš„è¯„è®ºä½œä¸ºç¤ºä¾‹
            negative_comments = [(c, s) for c, s in zip(valid_comments, scores) if s <= 0.4]
            if negative_comments:
                sample_comment = min(negative_comments, key=lambda x: x[1])[0].content[:60]
            else:
                sample_comment = valid_comments[0].content[:60] if valid_comments else ""

            results.append({
                "song_id": song.id,
                "song_name": song.name,
                "artist": song.artists[0].name if song.artists else "Unknown",
                "avg_sentiment": round(avg_score, 3),
                "negative_ratio": round(negative_ratio, 3),
                "wangyiyun_score": round(wangyiyun_score, 3),
                "sample_comment": sample_comment,
                "comment_count": len(valid_comments)
            })

        # æ’åº
        results.sort(key=lambda x: x['wangyiyun_score'], reverse=True)

        # æ·»åŠ æ’å
        for i, r in enumerate(results[:limit], 1):
            r['rank'] = i

        print(f"[OK] æ‰¾åˆ° {len(results[:limit])} é¦–ç½‘æŠ‘äº‘æ­Œæ›²")

        return results[:limit]

    finally:
        session.close()
